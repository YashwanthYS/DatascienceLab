{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BackPropagation [Yashwanth Y S - 1RV17CS194]\n",
    "\n",
    "Using Simple BackPropagation Neutral Network to detect Duke Breast Cancer\n",
    "\n",
    "Dataset from kaggle - We are going to use Duke Breast Cancer database that consists of [86] entries and [7129] attributes plus the class attribute that is located on the first column. The data is numerical and has no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Database raw shape (86,7130)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset and shape the dataset\n",
    "\n",
    "db = np.loadtxt(\"duke-breast-cancer.txt\")\n",
    "\"Database raw shape (%s,%s)\" % np.shape(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77, 7129), (9, 7129))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test train split\n",
    "\n",
    "np.random.shuffle(db)\n",
    "y = db[:, 0]\n",
    "x = np.delete(db, [0], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "np.shape(x_train),np.shape(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Neutral Network :\n",
    "\n",
    "The following are implemented : \n",
    "1. Sum function\n",
    "2. Activation function\n",
    "3. SoftMax function\n",
    "4. Recalculate Weights function\n",
    "5. Back-propagation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = np.zeros(72)\n",
    "weights = np.random.random((len(x[0]), 72))\n",
    "output_layer = np.zeros(2)\n",
    "hidden_weights = np.random.random((72, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_function(weights, index_locked_col, x):\n",
    "    result = 0\n",
    "    for i in range(0, len(x)):\n",
    "        result += x[i] * weights[i][index_locked_col]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_layer(layer, weights, x):\n",
    "    for i in range(0, len(layer)):\n",
    "        layer[i] = 1.7159 * np.tanh(2.0 * sum_function(weights, i, x) / 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(layer):\n",
    "    soft_max_output_layer = np.zeros(len(layer))\n",
    "    for i in range(0, len(layer)):\n",
    "        denominator = 0\n",
    "        for j in range(0, len(layer)):\n",
    "            denominator += np.exp(layer[j] - np.max(layer))\n",
    "        soft_max_output_layer[i] = np.exp(layer[i] - np.max(layer)) / denominator\n",
    "    return soft_max_output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_weights(learning_rate, weights, gradient, activation):\n",
    "    for i in range(0, len(weights)):\n",
    "        for j in range(0, len(weights[i])):\n",
    "            weights[i][j] = (learning_rate * gradient[j] * activation[i]) + weights[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(hidden_layer, output_layer, one_hot_encoding, learning_rate, x):\n",
    "    output_derivative = np.zeros(2)\n",
    "    output_gradient = np.zeros(2)\n",
    "    for i in range(0, len(output_layer)):\n",
    "        output_derivative[i] = (1.0 - output_layer[i]) * output_layer[i]\n",
    "    for i in range(0, len(output_layer)):\n",
    "        output_gradient[i] = output_derivative[i] * (one_hot_encoding[i] - output_layer[i])\n",
    "    hidden_derivative = np.zeros(72)\n",
    "    hidden_gradient = np.zeros(72)\n",
    "    for i in range(0, len(hidden_layer)):\n",
    "        hidden_derivative[i] = (1.0 - hidden_layer[i]) * (1.0 + hidden_layer[i])\n",
    "    for i in range(0, len(hidden_layer)):\n",
    "        sum_ = 0\n",
    "        for j in range(0, len(output_gradient)):\n",
    "            sum_ += output_gradient[j] * hidden_weights[i][j]\n",
    "        hidden_gradient[i] = sum_ * hidden_derivative[i]\n",
    "    recalculate_weights(learning_rate, hidden_weights, output_gradient, hidden_layer)\n",
    "    recalculate_weights(learning_rate, weights, hidden_gradient, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the neural newtork "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding = np.zeros((2,2))\n",
    "for i in range(0, len(one_hot_encoding)):\n",
    "    one_hot_encoding[i][i] = 1\n",
    "training_correct_answers = 0\n",
    "for i in range(0, len(x_train)):\n",
    "    activate_layer(hidden_layer, weights, x_train[i])\n",
    "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
    "    output_layer = soft_max(output_layer)\n",
    "    training_correct_answers += 1 if y_train[i] == np.argmax(output_layer) else 0\n",
    "    back_propagation(hidden_layer, output_layer, one_hot_encoding[int(y_train[i])], -1, x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers while testing: 8 / 9 (Accuracy = 0.8888888888888888) on Duke breast cancer database\n"
     ]
    }
   ],
   "source": [
    "testing_correct_answers = 0\n",
    "for i in range(0, len(x_test)):\n",
    "    activate_layer(hidden_layer, weights, x_test[i])\n",
    "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
    "    output_layer = soft_max(output_layer)\n",
    "    testing_correct_answers += 1 if y_test[i] == np.argmax(output_layer) else 0\n",
    "print(\"Correct answers while testing: %s / %s (Accuracy = %s) on %s database\" % (testing_correct_answers, len(x_test),\n",
    "                                                                                     testing_correct_answers/len(x_test), \"Duke breast cancer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
